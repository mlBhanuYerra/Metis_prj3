{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T15:04:32.029246Z",
     "start_time": "2019-10-20T15:04:31.217591Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, glob, re, scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "class GetStandfordCars:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loc=\"../Data/car_ims/\", labels_matlab_file =\"../Data/cars_annos.mat\"):\n",
    "        \n",
    "        self.car_images_location = loc\n",
    "        self.labels_mat = scipy.io.loadmat(labels_matlab_file)\n",
    "        \n",
    "        self.class_names = self.labels_mat['class_names'][0]\n",
    "        \n",
    "        self.max_pics = 16185\n",
    "        \n",
    "        # --- for future\n",
    "        #  Code to check if the 'loc' is a valid dataset\n",
    "        #  if not, download data and unzip\n",
    "        #  same for the labels matlab file\n",
    "        \n",
    "    \n",
    "    def bringAnnot(self, fileName):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        return ((self.labels_mat['annotations'][0][numb-1]))  \n",
    "    \n",
    "\n",
    "    def bringup_ClassLabel(self, fileName):\n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        #print(\"Class of image {}: {}\".format(fileName, class_labels[int(mat['annotations'][0][numb-1][5])-1][0]))\n",
    "        return self.class_names[int(self.labels_mat['annotations'][0][numb-1][5])-1][0]\n",
    "\n",
    "    \n",
    "    def getPath(self, number):\n",
    "        fileName  = str('0') * int(6 - len(str(number)))\n",
    "        fileName += str(number)+\".jpg\"\n",
    "        return (self.car_images_location + fileName)\n",
    "\n",
    "    \n",
    "    def getImgArray(self, number, target_size=(224, 224) ):\n",
    "        img_path =  self.getPath(number)\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    def getNextImgArray(self, target_size=(224, 224) ):\n",
    "        count = 0\n",
    "        \n",
    "        while count<self.max_pics:\n",
    "            count += 1        \n",
    "        \n",
    "            yield (count, self.getImgArray(count, target_size))\n",
    "    \n",
    "\n",
    "    def showRandomNxN(self, N):\n",
    "        '''\n",
    "        Function to plot the MNIST data on a grid of NxN\n",
    "        '''\n",
    "        plt.rcParams['figure.figsize'] = [30, 30]\n",
    "\n",
    "        listofRand = np.random.randint(1, 16185, size=int(N*N))\n",
    "\n",
    "        image_size = (128, 128)\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for i in range(0, N*N):\n",
    "            img = image.load_img(self.getPath(listofRand[i]), target_size=image_size)\n",
    "            ax = fig.add_subplot(N, N, i+1)\n",
    "            imgplot = ax.imshow(img)\n",
    "            ax.set_title(self.bringup_ClassLabel(listofRand[i]))\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show();\n",
    "\n",
    "        \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_ppi\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_ppi\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.resnet_v2 import preprocess_input as Res50V2_ppi\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptv3_ppi\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as moblv2_ppi\n",
    "\n",
    "PRETRAINED_MODELS = {\n",
    "    'VGG16': {\n",
    "        'model': VGG16,\n",
    "        'preprocess': vgg16_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'VGG19': {\n",
    "        'model': VGG19,\n",
    "        'preprocess': vgg19_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'ResNet50V2': {\n",
    "        'model': ResNet50V2,\n",
    "        'preprocess': Res50V2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'InceptionV3': {\n",
    "        'model': InceptionV3,\n",
    "        'preprocess': inceptv3_ppi,\n",
    "        'shape': (299, 299)\n",
    "    },\n",
    "    'MobileNetV2': {\n",
    "        'model': MobileNetV2,\n",
    "        'preprocess': moblv2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    }\n",
    "}\n",
    "\n",
    "class GetPretrainedFeatures:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn=\"VGG16\", database = GetStandfordCars(), layer = -1):\n",
    "        \n",
    "        self.cnn = cnn\n",
    "        self.db = database\n",
    "        self.layer_level = layer\n",
    "        \n",
    "    \n",
    "    def get_pretrained_features(self, limit=20, folder = \"../Data/features/\"):\n",
    "        \n",
    "        feature_df = pd.DataFrame()\n",
    "        \n",
    "        model = PRETRAINED_MODELS[self.cnn]['model'](weights='imagenet', include_top=True)\n",
    "        model_layer = Model(inputs=model.input, outputs=model.layers[self.layer_level].output)\n",
    "        preprocess = PRETRAINED_MODELS[self.cnn]['preprocess']\n",
    "        \n",
    "        input_shape = PRETRAINED_MODELS[self.cnn]['shape']\n",
    "        #print(input_shape)\n",
    "        \n",
    "        count = 0\n",
    "        for img in self.db.getNextImgArray(target_size=input_shape):\n",
    "            count += 1\n",
    "            x = preprocess(img[1])\n",
    "            features = model_layer.predict(x)\n",
    "            features = [[img[0]] + list(np.ndarray.flatten(features))]\n",
    "            feature_df = feature_df.append(pd.DataFrame(features), ignore_index=True)\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                feature_df.to_csv(folder + self.cnn + \"_\" + str(count//1000) + \".csv\")\n",
    "                print(\"Completed {} pics for {}\".format(count, self.cnn))\n",
    "                feature_df = pd.DataFrame()\n",
    "            \n",
    "            if count == limit:\n",
    "                    break\n",
    "        \n",
    "        feature_df.to_csv(folder + self.cnn + \"_rest\" + \".csv\")\n",
    "\n",
    "    def stitch_feature_files(self, features_folder = \"../Data/features/\", subscript=(1,16), rest=True,\n",
    "                            output_filename = False):\n",
    "        \"\"\"\n",
    "        Stitches the features extracted from the CNNs using get_pretrained_features() method\n",
    "        into a single csv file.\n",
    "        \n",
    "        Args:\n",
    "            features_folder = location of extracted files, assumes \"<cnn>_<x>.csv\" format\n",
    "            scubscript = a tuple with file subscipts from low to high (inclusive)\n",
    "                         as the <x> of the csv files\n",
    "            rest = Boolean to include \"rest\" as the <x> of the csv files\n",
    "            output_filename = output_filename to use. Uses <cnn>.csv as default. Specify a string.\n",
    "        \n",
    "        Returns:\n",
    "            a new csv file \n",
    "        \"\"\"\n",
    "        \n",
    "        #feature_df = pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        if not output_filename:\n",
    "            output_filename = self.cnn\n",
    "        \n",
    "        if \".\" not in output_filename:\n",
    "            output_filename = features_folder + output_filename + \".csv\"\n",
    "        else:\n",
    "            output_filename = features_folder + output_filename\n",
    "        \n",
    "        input_filename = features_folder + self.cnn + \"_\" + str(subscript[0]) + \".csv\"\n",
    "        features = np.genfromtxt(input_filename, delimiter=\",\", skip_header=1)\n",
    "        \n",
    "        for suffix in range(subscript[0]+1, subscript[1]+1):\n",
    "            input_filename = features_folder + self.cnn + \"_\" + str(suffix) + \".csv\"\n",
    "            #df = pd.read_csv(input_filename)\n",
    "            #feature_df = feature_df.append(df, ignore_index=True)\n",
    "            data = np.genfromtxt(input_filename, delimiter=\",\", skip_header=1)\n",
    "            features = np.concatenate((features, data), axis=0)\n",
    "        \n",
    "        if rest:\n",
    "            input_filename = features_folder + self.cnn + \"_rest\" + \".csv\"\n",
    "            data = np.genfromtxt(input_filename, delimiter=\",\", skip_header=1)\n",
    "            features = np.concatenate((features, data), axis=0)\n",
    "        \n",
    "        \n",
    "        feature_df = pd.DataFrame(features[:,1:])\n",
    "        feature_df.to_csv(output_filename)\n",
    "        #np.savetxt(output_filename, features[:,1:], delimiter=',')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T15:09:53.091634Z",
     "start_time": "2019-10-20T15:08:06.605944Z"
    }
   },
   "outputs": [],
   "source": [
    "for cnn in PRETRAINED_MODELS.keys():\n",
    "    pretrained = GetPretrainedFeatures(cnn=cnn, layer = -2)\n",
    "    pretrained.stitch_feature_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
