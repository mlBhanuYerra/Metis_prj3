{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T04:59:50.558479Z",
     "start_time": "2019-10-19T04:59:50.193553Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os, glob, re, scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "class GetStandfordCars:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, loc=\"../Data/car_ims/\", labels_matlab_file =\"../Data/cars_annos.mat\"):\n",
    "        \n",
    "        self.car_images_location = loc\n",
    "        self.labels_mat = scipy.io.loadmat(labels_matlab_file)\n",
    "        \n",
    "        self.class_names = self.labels_mat['class_names'][0]\n",
    "        \n",
    "        self.max_pics = 16185\n",
    "        \n",
    "        # --- for future\n",
    "        #  Code to check if the 'loc' is a valid dataset\n",
    "        #  if not, download data and unzip\n",
    "        #  same for the labels matlab file\n",
    "        \n",
    "    \n",
    "    def bringAnnot(self, fileName):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        return ((self.labels_mat['annotations'][0][numb-1]))  \n",
    "    \n",
    "\n",
    "    def bringup_ClassLabel(self, fileName):\n",
    "        if type(fileName) == str:\n",
    "            numb = int(re.sub(r'[^0-9]', '', fileName))\n",
    "        else:\n",
    "            numb = int(fileName)\n",
    "\n",
    "        #print(\"Class of image {}: {}\".format(fileName, class_labels[int(mat['annotations'][0][numb-1][5])-1][0]))\n",
    "        return self.class_names[int(self.labels_mat['annotations'][0][numb-1][5])-1][0]\n",
    "\n",
    "    \n",
    "    def getPath(self, number):\n",
    "        fileName  = str('0') * int(6 - len(str(number)))\n",
    "        fileName += str(number)+\".jpg\"\n",
    "        return (self.car_images_location + fileName)\n",
    "\n",
    "    \n",
    "    def getImgArray(self, number, target_size=(224, 224) ):\n",
    "        img_path =  self.getPath(number)\n",
    "        img = image.load_img(img_path, target_size=target_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "    def getNextImgArray(self, target_size=(224, 224) ):\n",
    "        count = 0\n",
    "        \n",
    "        while count<self.max_pics:\n",
    "            count += 1        \n",
    "        \n",
    "            yield (count, self.getImgArray(count, target_size))\n",
    "    \n",
    "\n",
    "    def showRandomNxN(self, N):\n",
    "        '''\n",
    "        Function to plot the MNIST data on a grid of NxN\n",
    "        '''\n",
    "        plt.rcParams['figure.figsize'] = [30, 30]\n",
    "\n",
    "        listofRand = np.random.randint(1, 16185, size=int(N*N))\n",
    "\n",
    "        image_size = (128, 128)\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for i in range(0, N*N):\n",
    "            img = image.load_img(self.getPath(listofRand[i]), target_size=image_size)\n",
    "            ax = fig.add_subplot(N, N, i+1)\n",
    "            imgplot = ax.imshow(img)\n",
    "            ax.set_title(self.bringup_ClassLabel(listofRand[i]))\n",
    "            ax.grid(False)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show();\n",
    "\n",
    "        \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input as vgg16_ppi\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input as vgg19_ppi\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "from keras.applications.resnet_v2 import preprocess_input as Res50V2_ppi\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input as inceptv3_ppi\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.applications.mobilenet_v2 import preprocess_input as moblv2_ppi\n",
    "\n",
    "PRETRAINED_MODELS = {\n",
    "    'VGG16': {\n",
    "        'model': VGG16,\n",
    "        'preprocess': vgg16_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'VGG19': {\n",
    "        'model': VGG19,\n",
    "        'preprocess': vgg19_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'ResNet50V2': {\n",
    "        'model': ResNet50V2,\n",
    "        'preprocess': Res50V2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    },\n",
    "    'InceptionV3': {\n",
    "        'model': InceptionV3,\n",
    "        'preprocess': inceptv3_ppi,\n",
    "        'shape': (299, 299)\n",
    "    },\n",
    "    'MobileNetV2': {\n",
    "        'model': MobileNetV2,\n",
    "        'preprocess': moblv2_ppi,\n",
    "        'shape': (224, 224)\n",
    "    }\n",
    "}\n",
    "\n",
    "class GetPretrainedFeatures:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cnn=\"VGG16\", database = GetStandfordCars(), layer = -1):\n",
    "        \n",
    "        self.cnn = cnn\n",
    "        self.db = database\n",
    "        self.layer_level = layer\n",
    "        \n",
    "    \n",
    "    def get_pretrained_features(self, limit=20, folder = \"../Data/features/\"):\n",
    "        \n",
    "        feature_df = pd.DataFrame()\n",
    "        \n",
    "        model = PRETRAINED_MODELS[self.cnn]['model'](weights='imagenet', include_top=True)\n",
    "        model_layer = Model(inputs=model.input, outputs=model.layers[self.layer_level].output)\n",
    "        preprocess = PRETRAINED_MODELS[self.cnn]['preprocess']\n",
    "        \n",
    "        input_shape = PRETRAINED_MODELS[self.cnn]['shape']\n",
    "        #print(input_shape)\n",
    "        \n",
    "        count = 0\n",
    "        for img in self.db.getNextImgArray(target_size=input_shape):\n",
    "            count += 1\n",
    "            x = preprocess(img[1])\n",
    "            features = model_layer.predict(x)\n",
    "            features = [[img[0]] + list(np.ndarray.flatten(features))]\n",
    "            feature_df = feature_df.append(pd.DataFrame(features), ignore_index=True)\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                feature_df.to_csv(folder + self.cnn + \"_\" + str(count//1000) + \".csv\")\n",
    "                print(\"Completed {} pics for {}\".format(count, self.cnn))\n",
    "                feature_df = pd.DataFrame()\n",
    "            \n",
    "            if count == limit:\n",
    "                    break\n",
    "        \n",
    "        feature_df.to_csv(folder + self.cnn + \"_rest\" + \".csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T10:08:47.634223Z",
     "start_time": "2019-10-19T04:59:53.535381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 pics for VGG16\n",
      "Completed 2000 pics for VGG16\n",
      "Completed 3000 pics for VGG16\n",
      "Completed 4000 pics for VGG16\n",
      "Completed 5000 pics for VGG16\n",
      "Completed 6000 pics for VGG16\n",
      "Completed 7000 pics for VGG16\n",
      "Completed 8000 pics for VGG16\n",
      "Completed 9000 pics for VGG16\n",
      "Completed 10000 pics for VGG16\n",
      "Completed 11000 pics for VGG16\n",
      "Completed 12000 pics for VGG16\n",
      "Completed 13000 pics for VGG16\n",
      "Completed 14000 pics for VGG16\n",
      "Completed 15000 pics for VGG16\n",
      "Completed 16000 pics for VGG16\n",
      "Completed 1000 pics for VGG19\n",
      "Completed 2000 pics for VGG19\n",
      "Completed 3000 pics for VGG19\n",
      "Completed 4000 pics for VGG19\n",
      "Completed 5000 pics for VGG19\n",
      "Completed 6000 pics for VGG19\n",
      "Completed 7000 pics for VGG19\n",
      "Completed 8000 pics for VGG19\n",
      "Completed 9000 pics for VGG19\n",
      "Completed 10000 pics for VGG19\n",
      "Completed 11000 pics for VGG19\n",
      "Completed 12000 pics for VGG19\n",
      "Completed 13000 pics for VGG19\n",
      "Completed 14000 pics for VGG19\n",
      "Completed 15000 pics for VGG19\n",
      "Completed 16000 pics for VGG19\n",
      "Completed 1000 pics for ResNet50V2\n",
      "Completed 2000 pics for ResNet50V2\n",
      "Completed 3000 pics for ResNet50V2\n",
      "Completed 4000 pics for ResNet50V2\n",
      "Completed 5000 pics for ResNet50V2\n",
      "Completed 6000 pics for ResNet50V2\n",
      "Completed 7000 pics for ResNet50V2\n",
      "Completed 8000 pics for ResNet50V2\n",
      "Completed 9000 pics for ResNet50V2\n",
      "Completed 10000 pics for ResNet50V2\n",
      "Completed 11000 pics for ResNet50V2\n",
      "Completed 12000 pics for ResNet50V2\n",
      "Completed 13000 pics for ResNet50V2\n",
      "Completed 14000 pics for ResNet50V2\n",
      "Completed 15000 pics for ResNet50V2\n",
      "Completed 16000 pics for ResNet50V2\n"
     ]
    }
   ],
   "source": [
    "limit_pics = False\n",
    "\n",
    "vgg16_pre = GetPretrainedFeatures(cnn=\"VGG16\", layer = -2)\n",
    "vgg16_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "vgg19_pre = GetPretrainedFeatures(cnn=\"VGG19\", layer = -2)\n",
    "vgg19_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "res50_pre = GetPretrainedFeatures(cnn=\"ResNet50V2\", layer = -2)\n",
    "res50_pre.get_pretrained_features(limit=limit_pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T14:33:58.701111Z",
     "start_time": "2019-10-19T13:02:28.292186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 1000 pics for InceptionV3\n",
      "Completed 2000 pics for InceptionV3\n",
      "Completed 3000 pics for InceptionV3\n",
      "Completed 4000 pics for InceptionV3\n",
      "Completed 5000 pics for InceptionV3\n",
      "Completed 6000 pics for InceptionV3\n",
      "Completed 7000 pics for InceptionV3\n",
      "Completed 8000 pics for InceptionV3\n",
      "Completed 9000 pics for InceptionV3\n",
      "Completed 10000 pics for InceptionV3\n",
      "Completed 11000 pics for InceptionV3\n",
      "Completed 12000 pics for InceptionV3\n",
      "Completed 13000 pics for InceptionV3\n",
      "Completed 14000 pics for InceptionV3\n",
      "Completed 15000 pics for InceptionV3\n",
      "Completed 16000 pics for InceptionV3\n",
      "Completed 1000 pics for MobileNetV2\n",
      "Completed 2000 pics for MobileNetV2\n",
      "Completed 3000 pics for MobileNetV2\n",
      "Completed 4000 pics for MobileNetV2\n",
      "Completed 5000 pics for MobileNetV2\n",
      "Completed 6000 pics for MobileNetV2\n",
      "Completed 7000 pics for MobileNetV2\n",
      "Completed 8000 pics for MobileNetV2\n",
      "Completed 9000 pics for MobileNetV2\n",
      "Completed 10000 pics for MobileNetV2\n",
      "Completed 11000 pics for MobileNetV2\n",
      "Completed 12000 pics for MobileNetV2\n",
      "Completed 13000 pics for MobileNetV2\n",
      "Completed 14000 pics for MobileNetV2\n",
      "Completed 15000 pics for MobileNetV2\n",
      "Completed 16000 pics for MobileNetV2\n"
     ]
    }
   ],
   "source": [
    "inception_pre = GetPretrainedFeatures(cnn=\"InceptionV3\", layer = -2)\n",
    "inception_pre.get_pretrained_features(limit=limit_pics)\n",
    "\n",
    "mbnet_pre = GetPretrainedFeatures(cnn=\"MobileNetV2\", layer = -2)\n",
    "mbnet_pre.get_pretrained_features(limit=limit_pics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
